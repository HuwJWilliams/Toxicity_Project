# Visualise Class — User Guide

## Overview

The `Visualise` class centralises all plotting and visualisation functions used throughout this project.  
It provides a consistent interface for creating, formatting, and saving a variety of plots used to analyse model and descriptor performance.

All plots can optionally be saved automatically by enabling the `save_all` flag or by passing `save_plot=True` per method.

---

## Class Initialization

### `__init__(save_all: bool = False, save_path: Path = None)`

Initializes the plotting utility class.

#### Parameters
| Name | Type | Description |
|------|------|-------------|
| `save_all` | `bool` | If `True`, automatically saves all plots generated by the class without requiring `save_plot=True` for each function. Default = `False`. |
| `save_path` | `Path` | Default directory to save plots. If `None`, plots are saved to the current working directory. Default = `None`. |

---

## Helper Functions

### `_savePlot(save_plot: bool, save_path: Union[str, Path], save_fname: str, dpi: int, description: str = "Saved plot", fig: plt.Figure \| None = None)`

Saves a matplotlib plot.

#### Parameters
| Name | Type | Description |
|------|------|-------------|
| `save_plot` | `bool` | Whether to save the plot. |
| `save_path` | `str` \| `Path` | Directory to save the figure in. |
| `save_fname` | `str` | Filename (extension optional). |
| `dpi` | `int` | Image resolution (dots per inch). |
| `description` | `str` | Description printed when saving the file. |
| `fig` | `plt.Figure` | Optional. The figure object to save. If `None`, saves the current active figure. |

---

### `_loadData(df, index_col=0, exclude=[], wildcard='*') → pd.DataFrame`

Flexibly loads a dataset from a file path, wildcard pattern, or DataFrame.

#### Parameters
| Name | Type | Description |
|------|------|-------------|
| `df` | `str` \| `Path` \| `pd.DataFrame` | Path, pattern (with wildcard), or DataFrame to load. |
| `index_col` | `int` \| `str` | Column to use as index when reading CSV. |
| `exclude` | `list[str]` | Column names to drop after loading. |
| `wildcard` | `str` | Wildcard pattern character (`*` by default). |

#### Returns
| Type | Description |
|------|--------------|
| `pd.DataFrame` | The loaded and optionally filtered DataFrame. |

---

### `_getColour(name: str) → tuple`

Retrieves the RGBA colour associated with a given label.

#### Parameters
| Name | Type | Description |
|------|------|-------------|
| `name` | `str` | Label to look up in the internal colour map. |

#### Returns
| Type | Description |
|------|--------------|
| `tuple` | RGBA tuple representing the colour `(R, G, B, A)`. |

---

## Plotting Functions

Each of these generates a specific visualisation and can optionally save figures to disk.

---

### `plotPCA(data_dict, n_components=5, ...)`

Plots PCA scatterplots, density plots, and loadings for one or more datasets.  
Automatically identifies numeric columns shared across datasets and performs scaling, PCA decomposition, and visualisation.

**Use case:** comparing distribution overlap between feature spaces.

---

### `plotModelPerformanceBars(base_path, model_jsons, model_labels, ...)`

Generates bar plots comparing model performance metrics (e.g., R², Pearson r, RMSE, Bias) across models.

**Use case:** quick visual comparison of performance metrics.

---

### `plotGroupHeatmaps(data, descriptor_groups, metric='Pearson_r', ...)`

Plots a heatmap per descriptor group showing metric performance values.

**Use case:** identifying performance patterns across descriptor subsets.

---

### `plotBoxPlots(*data_dfs, trained_labels, predicted_labels, ...)`

Generates box plots showing model transferability between training and prediction feature sets.

**Use case:** visualising cross-descriptor model performance consistency.

---

### `plotGroupBar(*group_dfs, labels, ...)`

Plots grouped bar charts comparing model performance by descriptor groups.

**Use case:** comparing average descriptor group performance across models.

---

### `plotGroupRadar(group_perf_df, ...)`

Creates a radar plot of group performances with dual radial scales (0–1 and 0.5–1).

**Use case:** visual summary of descriptor group strengths.

---

### `plotBar(data, x_label, y_label, ...)`

Generic bar plotting utility.

**Use case:** quick visualisation of any single-metric DataFrame.

---

### `plotFeatureImportance(data, x_col='Importance', y_col='Feature', ...)`

Plots ranked feature importance from trained models.

**Use case:** interpreting model explainability outputs (e.g., feature weights, SHAP, permutation importances).

---

### `plotMultiTaskPerformance(data, x_col, y_col, ...)`

Plots how models trained on one feature representation perform when predicting another.

**Use case:** visualising cross-task or cross-domain transferability.

---

### `computeGroupPerf(data, descriptor_groups, metrics, exclude=None) → pd.DataFrame`

Computes average performance metrics per descriptor group.

#### Returns
| Type | Description |
|------|--------------|
| `pd.DataFrame` | DataFrame of average metric values across descriptor groups. |

---

## Example Usage

```python
from vis import Visualise
import pandas as pd
from pathlib import Path

# Initialize class
vis = Visualise(save_all=True, save_path=Path("./plots"))

# Example: PCA across feature sets
data_dict = {
    "rdkit": Path("results/rdkit_data.csv"),
    "mordred": Path("results/mordred_data.csv")
}
fig, pca_df, loadings_df = vis.plotPCA(data_dict=data_dict, n_components=3, save_plot=True)
